{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU: ', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Attention Module used to perform self-attention operation allowing the model to attend\n",
    "    information from different representation subspaces on an input sequence of embeddings.\n",
    "    The sequence of operations is as follows :-\n",
    "\n",
    "    Input -> Query, Key, Value -> ReshapeHeads -> Query.TransposedKey -> Softmax -> Dropout\n",
    "    -> AttentionScores.Value -> ReshapeHeadsBack -> Output\n",
    "\n",
    "    Args:\n",
    "        embed_dim: Dimension size of the hidden embedding\n",
    "        heads: Number of parallel attention heads (Default=8)\n",
    "        activation: Optional activation function to be applied to the input while\n",
    "                    transforming to query, key and value matrixes (Default=None)\n",
    "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
    "\n",
    "    Methods:\n",
    "        _reshape_heads(inp) :-\n",
    "        Changes the input sequence embeddings to reduced dimension according to the number\n",
    "        of attention heads to parallelize attention operation\n",
    "        (batch_size, seq_len, embed_dim) -> (batch_size * heads, seq_len, reduced_dim)\n",
    "\n",
    "        _reshape_heads_back(inp) :-\n",
    "        Changes the reduced dimension due to parallel attention heads back to the original\n",
    "        embedding size\n",
    "        (batch_size * heads, seq_len, reduced_dim) -> (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        forward(inp) :-\n",
    "        Performs the self-attention operation on the input sequence embedding.\n",
    "        Returns the output of self-attention as well as atttention scores\n",
    "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim), (batch_size * heads, seq_len, seq_len)\n",
    "\n",
    "    Examples:\n",
    "        >>> attention = Attention(embed_dim, heads, activation, dropout)\n",
    "        >>> out, weights = attention(inp)\n",
    "    '''\n",
    "    def __init__(self, embed_dim, heads=8, activation=None, dropout=0.1):\n",
    "        super(Attention, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        if activation == 'relu':\n",
    "            self.activation = nn.ReLU()\n",
    "        else:\n",
    "            self.activation = nn.Identity()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # inp: (batch_size, seq_len, embed_dim)\n",
    "        batch_size, seq_len, embed_dim = inp.size()\n",
    "        assert embed_dim == self.embed_dim\n",
    "\n",
    "        query = self.activation(self.query(inp))\n",
    "        key   = self.activation(self.key(inp))\n",
    "        value = self.activation(self.value(inp))\n",
    "\n",
    "        # output of _reshape_heads(): (batch_size * heads, seq_len, reduced_dim) | reduced_dim = embed_dim // heads\n",
    "        query = self._reshape_heads(query)\n",
    "        key   = self._reshape_heads(key)\n",
    "        value = self._reshape_heads(value)\n",
    "\n",
    "        # attention_scores: (batch_size * heads, seq_len, seq_len) | Softmaxed along the last dimension\n",
    "        attention_scores = self.softmax(torch.matmul(query, key.transpose(1, 2)))\n",
    "\n",
    "        # out: (batch_size * heads, seq_len, reduced_dim)\n",
    "        out = torch.matmul(self.dropout(attention_scores), value)\n",
    "\n",
    "        # output of _reshape_heads_back(): (batch_size, seq_len, embed_size)\n",
    "        out = self._reshape_heads_back(out)\n",
    "\n",
    "        return out, attention_scores\n",
    "\n",
    "    def _reshape_heads(self, inp):\n",
    "        # inp: (batch_size, seq_len, embed_dim)\n",
    "        batch_size, seq_len, embed_dim = inp.size()\n",
    "\n",
    "        reduced_dim = self.embed_dim // self.heads\n",
    "        assert reduced_dim * self.heads == self.embed_dim\n",
    "        out = inp.reshape(batch_size, seq_len, self.heads, reduced_dim)\n",
    "        out = out.permute(0, 2, 1, 3)\n",
    "        out = out.reshape(-1, seq_len, reduced_dim)\n",
    "\n",
    "        # out: (batch_size * heads, seq_len, reduced_dim)\n",
    "        return out\n",
    "\n",
    "    def _reshape_heads_back(self, inp):\n",
    "        # inp: (batch_size * heads, seq_len, reduced_dim) | reduced_dim = embed_dim // heads\n",
    "        batch_size_mul_heads, seq_len, reduced_dim = inp.size()\n",
    "        batch_size = batch_size_mul_heads // self.heads\n",
    "\n",
    "        out = inp.reshape(batch_size, self.heads, seq_len, reduced_dim)\n",
    "        out = out.permute(0, 2, 1, 3)\n",
    "        out = out.reshape(batch_size, seq_len, self.embed_dim)\n",
    "\n",
    "        # out: (batch_size, seq_len, embed_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Dropout should be used after second Linear Layer\n",
    "class FeedForward(nn.Module):\n",
    "    '''\n",
    "    FeedForward Network with two sequential linear layers with GELU activation function\n",
    "    ,applied to the output of self attention operation. The sequence of operations is as\n",
    "    follows :-\n",
    "\n",
    "    Input -> FC1 -> GELU -> Dropout -> FC2 -> Output\n",
    "\n",
    "    Args:\n",
    "        embed_dim: Dimension size of the hidden embedding\n",
    "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
    "                           and then scaled back to capture richer information (Default=1)\n",
    "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
    "\n",
    "    Methods:\n",
    "        forward(inp) :-\n",
    "        Applies the sequence of operations mentioned above.\n",
    "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim)\n",
    "\n",
    "    Examples:\n",
    "        >>> FF = FeedForward(8, 1)\n",
    "        >>> out = FF(inp)\n",
    "    '''\n",
    "    def __init__(self, embed_dim, forward_expansion=1, dropout=0.1):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim * forward_expansion)\n",
    "        self.activation = nn.GELU()\n",
    "        self.fc2 = nn.Linear(embed_dim * forward_expansion, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # inp: (batch_size, seq_len, embed_dim)\n",
    "        batch_size, seq_len, embed_dim = inp.size()\n",
    "        assert embed_dim == self.embed_dim\n",
    "\n",
    "        out = self.dropout(self.activation(self.fc1(inp)))\n",
    "        # out = self.dropout(self.fc2(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        # out: (batch_size, seq_len, embed_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    '''\n",
    "    Transformer Block combines both the attention module and the feed forward module with layer\n",
    "    normalization, dropout and residual connections. The sequence of operations is as follows :-\n",
    "\n",
    "    Input -> LayerNorm1 -> Attention -> Residual -> LayerNorm2 -> FeedForward -> Output\n",
    "      |                                   |  |                                      |\n",
    "      |-------------Addition--------------|  |---------------Addition---------------|\n",
    "\n",
    "    Args:\n",
    "        embed_dim: Dimension size of the hidden embedding\n",
    "        heads: Number of parallel attention heads (Default=8)\n",
    "        activation: Optional activation function to be applied to the input while\n",
    "                    transforming to query, key and value matrixes (Default=None)\n",
    "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
    "                           and then scaled back to capture richer information (Default=1)\n",
    "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
    "\n",
    "    Methods:\n",
    "        forward(inp) :-\n",
    "        Applies the sequence of operations mentioned above.\n",
    "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim)\n",
    "\n",
    "    Examples:\n",
    "        >>> TB = TransformerBlock(embed_dim, heads, activation, forward_expansion, dropout)\n",
    "        >>> out = TB(inp)\n",
    "    '''\n",
    "    def __init__(self, embed_dim, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attention = Attention(embed_dim, heads, activation, dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.feed_forward = FeedForward(embed_dim, forward_expansion, dropout)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # inp: (batch_size, seq_len, embed_dim)\n",
    "        batch_size, seq_len, embed_dim = inp.size()\n",
    "        assert embed_dim == self.embed_dim\n",
    "\n",
    "        res = inp\n",
    "        out = self.norm1(inp)\n",
    "        out, _ = self.attention(out)\n",
    "        out = out + res\n",
    "\n",
    "        res = out\n",
    "        out = self.norm2(out)\n",
    "        out = self.feed_forward(out)\n",
    "        out = out + res\n",
    "\n",
    "        # out: (batch_size, seq_len, embed_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    '''\n",
    "    Transformer combines multiple layers of Transformer Blocks in a sequential manner. The sequence\n",
    "    of the operations is as follows -\n",
    "\n",
    "    Input -> TB1 -> TB2 -> .......... -> TBn (n being the number of layers) -> Output\n",
    "\n",
    "    Args:\n",
    "        embed_dim: Dimension size of the hidden embedding\n",
    "        layers: Number of Transformer Blocks in the Transformer\n",
    "        heads: Number of parallel attention heads (Default=8)\n",
    "        activation: Optional activation function to be applied to the input while\n",
    "                    transforming to query, key and value matrixes (Default=None)\n",
    "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
    "                           and then scaled back to capture richer information (Default=1)\n",
    "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
    "\n",
    "    Methods:\n",
    "        forward(inp) :-\n",
    "        Applies the sequence of operations mentioned above.\n",
    "        (batch_size, seq_len, embed_dim) -> (batch_size, seq_len, embed_dim)\n",
    "\n",
    "    Examples:\n",
    "        >>> transformer = Transformer(embed_dim, layers, heads, activation, forward_expansion, dropout)\n",
    "        >>> out = transformer(inp)\n",
    "    '''\n",
    "    def __init__(self, embed_dim, layers, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.trans_blocks = nn.ModuleList(\n",
    "            [TransformerBlock(embed_dim, heads, activation, forward_expansion, dropout) for i in range(layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # inp: (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        out = inp\n",
    "        for block in self.trans_blocks:\n",
    "            out = block(out)\n",
    "\n",
    "        # out: (batch_size, seq_len, embed_dim)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not Exactly Same as Paper\n",
    "class ClassificationHead(nn.Module):\n",
    "    '''\n",
    "    Classification Head attached to the first sequence token which is used as the arbitrary\n",
    "    classification token and used to optimize the transformer model by applying Cross-Entropy\n",
    "    loss. The sequence of operations is as follows :-\n",
    "\n",
    "    Input -> FC1 -> GELU -> Dropout -> FC2 -> Output\n",
    "\n",
    "    Args:\n",
    "        embed_dim: Dimension size of the hidden embedding\n",
    "        classes: Number of classification classes in the dataset\n",
    "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
    "\n",
    "    Methods:\n",
    "        forward(inp) :-\n",
    "        Applies the sequence of operations mentioned above.\n",
    "        (batch_size, embed_dim) -> (batch_size, classes)\n",
    "\n",
    "    Examples:\n",
    "        >>> CH = ClassificationHead(embed_dim, classes, dropout)\n",
    "        >>> out = CH(inp)\n",
    "    '''\n",
    "    def __init__(self, embed_dim, classes, dropout=0.1):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.classes = classes\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim // 2)\n",
    "        self.activation = nn.GELU()\n",
    "        self.fc2 = nn.Linear(embed_dim // 2, classes)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # inp: (batch_size, embed_dim)\n",
    "        batch_size, embed_dim = inp.size()\n",
    "        assert embed_dim == self.embed_dim\n",
    "\n",
    "        out = self.dropout(self.activation(self.fc1(inp)))\n",
    "        # out = self.softmax(self.fc2(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        # out: (batch_size, classes)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    '''\n",
    "    Vision Transformer is the complete end to end model architecture which combines all the above modules\n",
    "    in a sequential manner. The sequence of the operations is as follows -\n",
    "\n",
    "    Input -> CreatePatches -> ClassToken, PatchToEmbed , PositionEmbed -> Transformer -> ClassificationHead -> Output\n",
    "                                   |            | |                |\n",
    "                                   |---Concat---| |----Addition----|\n",
    "\n",
    "    Args:\n",
    "        patch_size: Length of square patch size\n",
    "        max_len: Max length of learnable positional embedding\n",
    "        embed_dim: Dimension size of the hidden embedding\n",
    "        classes: Number of classes in the dataset\n",
    "        layers: Number of Transformer Blocks in the Transformer\n",
    "        channels: Number of channels in the input (Default=3)\n",
    "        heads: Number of parallel attention heads (Default=8)\n",
    "        activation: Optional activation function to be applied to the input while\n",
    "                    transforming to query, key and value matrixes (Default=None)\n",
    "        forward_expansion: The scale used to transform the input embedding to a higher dimension\n",
    "                           and then scaled back to capture richer information (Default=1)\n",
    "        dropout: Dropout value for the layer on attention_scores (Default=0.1)\n",
    "\n",
    "    Methods:\n",
    "        forward(inp) :-\n",
    "        Applies the sequence of operations mentioned above.\n",
    "        It outputs the classification output as well as the sequence output of the transformer\n",
    "        (batch_size, channels, width, height) -> (batch_size, classes), (batch_size, seq_len+1, embed_dim)\n",
    "\n",
    "    Examples:\n",
    "        >>> ViT = VisionTransformer(atch_size, max_len, embed_dim, classes, layers, channels, heads, activation, forward_expansion, dropout)\n",
    "        >>> class_out, hidden_seq = ViT(inp)\n",
    "    '''\n",
    "    def __init__(self, patch_size, max_len, embed_dim, classes, layers, channels=3, heads=8, activation=None, forward_expansion=1, dropout=0.1):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.name = 'VisionTransformer'\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.channels = channels\n",
    "        self.patch_to_embed = nn.Linear(patch_size * patch_size * channels, embed_dim)\n",
    "        self.position_embed = nn.Parameter(torch.randn((max_len, embed_dim)))\n",
    "        self.transformer = Transformer(embed_dim, layers, heads, activation, forward_expansion, dropout)\n",
    "        self.classification_head = ClassificationHead(embed_dim, classes)\n",
    "        self.class_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # inp: (batch_size, channels, width, height)\n",
    "        batch_size, channels, width, height = inp.size()\n",
    "        assert channels == self.channels\n",
    "\n",
    "        out = inp.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size).contiguous()\n",
    "        out = out.view(batch_size, channels, -1, self.patch_size, self.patch_size)\n",
    "        out = out.permute(0, 2, 3, 4, 1)\n",
    "        # out: (batch_size, seq_len, patch_size, patch_size, channels) | seq_len would be (width*height)/(patch_size**2)\n",
    "        batch_size, seq_len, patch_size, _, channels = out.size()\n",
    "\n",
    "        out = out.reshape(batch_size, seq_len, -1)\n",
    "        out = self.patch_to_embed(out)\n",
    "        # out: (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        class_token = self.class_token.expand(batch_size, -1, -1)\n",
    "        out = torch.cat([class_token, out], dim=1)\n",
    "        # out: (batch_size, seq_len+1, embed_dim)\n",
    "\n",
    "        position_embed = self.position_embed[:seq_len+1]\n",
    "        position_embed = position_embed.unsqueeze(0).expand(batch_size, seq_len+1, self.embed_dim)\n",
    "        out = out + position_embed\n",
    "        # out: (batch_size, seq_len+1, embed_dim) | Added Positional Embeddings\n",
    "\n",
    "        out = self.transformer(out)\n",
    "        # out: (batch_size, seq_len+1, embed_dim)\n",
    "        class_token = out[:, 0]\n",
    "        # class_token: (batch_size, embed_dim)\n",
    "\n",
    "        class_out = self.classification_head(class_token)\n",
    "        # class_out: (batch_size, classes)\n",
    "\n",
    "        return class_out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations of all the constants used in the training and testing process\n",
    "\n",
    "lr = 0.003\n",
    "batch_size = 128\n",
    "num_workers = 2\n",
    "shuffle = True\n",
    "patch_size = 4\n",
    "image_sz = 32\n",
    "max_len = 65 # All sequences must be less than 1000 including class token\n",
    "embed_dim = 128\n",
    "classes = 10\n",
    "layers = 6\n",
    "channels = 3\n",
    "heads = 8\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_to_embed): Linear(in_features=48, out_features=128, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (trans_blocks): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): Attention(\n",
       "          (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (activation): Identity()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): FeedForward(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activation): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): ClassificationHead(\n",
       "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VisionTransformer(\n",
    "    patch_size=patch_size,\n",
    "    max_len=max_len,\n",
    "    embed_dim=embed_dim,\n",
    "    classes=classes,\n",
    "    layers=layers,\n",
    "    channels=channels,\n",
    "    heads=heads)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "from torch.amp import GradScaler\n",
    "model.no_custom_backward = False\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=len(trainloader), epochs=epochs)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 522,058\n"
     ]
    }
   ],
   "source": [
    "# Get model parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size: 1.99 MB\n"
     ]
    }
   ],
   "source": [
    "# Estimate model size (assuming float32 parameters, 4 bytes each)\n",
    "model_size_mb = (total_params * 4) / (1024 * 1024)\n",
    "print(f\"Model Size: {model_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training without saving\n",
    "from tqdm import tqdm\n",
    "def train(epoch):\n",
    "    print(\"\\nTraining Epoch: %d\" % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(tqdm(trainloader)):\n",
    "        # We do not need to specify AMP autocast in forward pass here since\n",
    "        # that is taken care of already in the forward of individual modules.\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs,_ = model(inputs)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # standard pytorch AMP training setup\n",
    "        # scaler also works without amp training.\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print(f\"Training Accuracy:{100.*correct/total: 0.2f}\")\n",
    "    print(f\"Training Loss:{train_loss/(batch_idx+1): 0.3f}\")\n",
    "    return 100.0 * correct / total, train_loss / (batch_idx + 1)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    print(\"\\nTesting Epoch: %d\" % epoch)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(testloader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs,_ = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(f\"Test Accuracy:{100.*correct/total: 0.2f}\")\n",
    "        print(f\"Test Loss:{test_loss/(batch_idx+1): 0.3f}\")\n",
    "        return 100.0 * correct / total, test_loss / (batch_idx + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from thop import profile\n",
    "# dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "# flops, _ = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "# print(f\"FLOPs per inference step: {flops / 1e9:.2f} GFLOPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir = './baseline_vit_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 28.15\n",
      "Training Loss: 1.936\n",
      "\n",
      "Testing Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 69.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 39.64\n",
      "Test Loss: 1.670\n",
      "Time taken for epoch 1: 13.86 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 1: 53.4587\n",
      "\n",
      "Training Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 38.93\n",
      "Training Loss: 1.666\n",
      "\n",
      "Testing Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 68.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 46.89\n",
      "Test Loss: 1.476\n",
      "Time taken for epoch 2: 13.61 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 2: 53.4587\n",
      "\n",
      "Training Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 42.87\n",
      "Training Loss: 1.564\n",
      "\n",
      "Testing Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 68.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 49.29\n",
      "Test Loss: 1.413\n",
      "Time taken for epoch 3: 13.57 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 3: 53.4587\n",
      "\n",
      "Training Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 45.16\n",
      "Training Loss: 1.506\n",
      "\n",
      "Testing Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.91\n",
      "Test Loss: 1.366\n",
      "Time taken for epoch 4: 13.53 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 4: 53.4587\n",
      "\n",
      "Training Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 27.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 46.96\n",
      "Training Loss: 1.459\n",
      "\n",
      "Testing Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 51.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 51.99\n",
      "Test Loss: 1.325\n",
      "Time taken for epoch 5: 15.57 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 5: 53.4587\n",
      "\n",
      "Training Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 48.28\n",
      "Training Loss: 1.424\n",
      "\n",
      "Testing Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 53.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 53.18\n",
      "Test Loss: 1.306\n",
      "Time taken for epoch 6: 16.05 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 6: 53.4587\n",
      "\n",
      "Training Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 49.84\n",
      "Training Loss: 1.393\n",
      "\n",
      "Testing Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 61.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 53.72\n",
      "Test Loss: 1.291\n",
      "Time taken for epoch 7: 16.01 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 7: 53.4587\n",
      "\n",
      "Training Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 50.21\n",
      "Training Loss: 1.371\n",
      "\n",
      "Testing Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 55.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 54.99\n",
      "Test Loss: 1.254\n",
      "Time taken for epoch 8: 16.12 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 8: 53.4587\n",
      "\n",
      "Training Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 51.28\n",
      "Training Loss: 1.347\n",
      "\n",
      "Testing Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 57.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 55.92\n",
      "Test Loss: 1.232\n",
      "Time taken for epoch 9: 16.13 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 9: 53.4587\n",
      "\n",
      "Training Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 52.55\n",
      "Training Loss: 1.317\n",
      "\n",
      "Testing Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 56.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 56.58\n",
      "Test Loss: 1.211\n",
      "Time taken for epoch 10: 15.93 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 10: 53.4587\n",
      "\n",
      "Training Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:14<00:00, 26.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 52.95\n",
      "Training Loss: 1.298\n",
      "\n",
      "Testing Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 56.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.16\n",
      "Test Loss: 1.187\n",
      "Time taken for epoch 11: 16.14 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 11: 53.4587\n",
      "\n",
      "Training Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 30.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 53.67\n",
      "Training Loss: 1.282\n",
      "\n",
      "Testing Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 70.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.77\n",
      "Test Loss: 1.176\n",
      "Time taken for epoch 12: 14.06 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 12: 53.4587\n",
      "\n",
      "Training Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 54.30\n",
      "Training Loss: 1.265\n",
      "\n",
      "Testing Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 70.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 57.95\n",
      "Test Loss: 1.168\n",
      "Time taken for epoch 13: 13.57 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 13: 53.4587\n",
      "\n",
      "Training Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 54.91\n",
      "Training Loss: 1.249\n",
      "\n",
      "Testing Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 66.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 58.82\n",
      "Test Loss: 1.143\n",
      "Time taken for epoch 14: 13.50 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 14: 53.4587\n",
      "\n",
      "Training Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 55.38\n",
      "Training Loss: 1.231\n",
      "\n",
      "Testing Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 61.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 58.82\n",
      "Test Loss: 1.146\n",
      "Time taken for epoch 15: 13.55 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 15: 53.4587\n",
      "\n",
      "Training Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 32.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.04\n",
      "Training Loss: 1.217\n",
      "\n",
      "Testing Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 60.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 59.63\n",
      "Test Loss: 1.136\n",
      "Time taken for epoch 16: 13.30 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 16: 53.4587\n",
      "\n",
      "Training Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 56.31\n",
      "Training Loss: 1.212\n",
      "\n",
      "Testing Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 63.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 59.56\n",
      "Test Loss: 1.125\n",
      "Time taken for epoch 17: 13.43 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 17: 53.4587\n",
      "\n",
      "Training Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 57.08\n",
      "Training Loss: 1.190\n",
      "\n",
      "Testing Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 72.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 59.55\n",
      "Test Loss: 1.122\n",
      "Time taken for epoch 18: 13.40 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 18: 53.4587\n",
      "\n",
      "Training Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 57.35\n",
      "Training Loss: 1.183\n",
      "\n",
      "Testing Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 75.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 60.13\n",
      "Test Loss: 1.093\n",
      "Time taken for epoch 19: 13.50 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 19: 53.4587\n",
      "\n",
      "Training Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 57.96\n",
      "Training Loss: 1.171\n",
      "\n",
      "Testing Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 71.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 60.42\n",
      "Test Loss: 1.099\n",
      "Time taken for epoch 20: 13.65 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 20: 53.4587\n",
      "\n",
      "Training Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:12<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 57.92\n",
      "Training Loss: 1.163\n",
      "\n",
      "Testing Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 70.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.11\n",
      "Test Loss: 1.085\n",
      "Time taken for epoch 21: 13.58 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 21: 53.4587\n",
      "\n",
      "Training Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 33.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 58.82\n",
      "Training Loss: 1.150\n",
      "\n",
      "Testing Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.47\n",
      "Test Loss: 1.072\n",
      "Time taken for epoch 22: 12.53 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 22: 53.4587\n",
      "\n",
      "Training Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 59.28\n",
      "Training Loss: 1.135\n",
      "\n",
      "Testing Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.67\n",
      "Test Loss: 1.067\n",
      "Time taken for epoch 23: 8.89 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 23: 53.4587\n",
      "\n",
      "Training Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 59.42\n",
      "Training Loss: 1.128\n",
      "\n",
      "Testing Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 93.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.68\n",
      "Test Loss: 1.063\n",
      "Time taken for epoch 24: 9.17 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 24: 53.4587\n",
      "\n",
      "Training Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 59.77\n",
      "Training Loss: 1.120\n",
      "\n",
      "Testing Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 110.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.77\n",
      "Test Loss: 1.053\n",
      "Time taken for epoch 25: 9.01 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 25: 53.4587\n",
      "\n",
      "Training Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 60.39\n",
      "Training Loss: 1.106\n",
      "\n",
      "Testing Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 125.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.96\n",
      "Test Loss: 1.053\n",
      "Time taken for epoch 26: 8.86 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 26: 53.4587\n",
      "\n",
      "Training Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 60.68\n",
      "Training Loss: 1.095\n",
      "\n",
      "Testing Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 104.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.10\n",
      "Test Loss: 1.037\n",
      "Time taken for epoch 27: 9.34 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 27: 53.4587\n",
      "\n",
      "Training Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 61.08\n",
      "Training Loss: 1.086\n",
      "\n",
      "Testing Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.78\n",
      "Test Loss: 1.022\n",
      "Time taken for epoch 28: 8.91 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 28: 53.4587\n",
      "\n",
      "Training Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 61.47\n",
      "Training Loss: 1.080\n",
      "\n",
      "Testing Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 91.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.14\n",
      "Test Loss: 1.015\n",
      "Time taken for epoch 29: 8.90 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 29: 53.4587\n",
      "\n",
      "Training Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 61.83\n",
      "Training Loss: 1.073\n",
      "\n",
      "Testing Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 109.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.36\n",
      "Test Loss: 1.020\n",
      "Time taken for epoch 30: 9.13 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 30: 53.4587\n",
      "\n",
      "Training Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 61.69\n",
      "Training Loss: 1.065\n",
      "\n",
      "Testing Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 115.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.11\n",
      "Test Loss: 0.999\n",
      "Time taken for epoch 31: 8.88 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 31: 53.4587\n",
      "\n",
      "Training Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 62.37\n",
      "Training Loss: 1.050\n",
      "\n",
      "Testing Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 107.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.21\n",
      "Test Loss: 0.995\n",
      "Time taken for epoch 32: 9.40 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 32: 53.4587\n",
      "\n",
      "Training Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 62.64\n",
      "Training Loss: 1.047\n",
      "\n",
      "Testing Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 116.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.14\n",
      "Test Loss: 0.994\n",
      "Time taken for epoch 33: 8.80 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 33: 53.4587\n",
      "\n",
      "Training Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 63.07\n",
      "Training Loss: 1.039\n",
      "\n",
      "Testing Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 95.14it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.63\n",
      "Test Loss: 0.985\n",
      "Time taken for epoch 34: 8.88 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 34: 53.4587\n",
      "\n",
      "Training Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 63.39\n",
      "Training Loss: 1.026\n",
      "\n",
      "Testing Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.30\n",
      "Test Loss: 0.985\n",
      "Time taken for epoch 35: 9.25 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 35: 53.4587\n",
      "\n",
      "Training Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 63.34\n",
      "Training Loss: 1.020\n",
      "\n",
      "Testing Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.60\n",
      "Test Loss: 0.968\n",
      "Time taken for epoch 36: 8.91 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 36: 53.4587\n",
      "\n",
      "Training Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 63.96\n",
      "Training Loss: 1.011\n",
      "\n",
      "Testing Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 92.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.12\n",
      "Test Loss: 0.968\n",
      "Time taken for epoch 37: 9.22 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 37: 53.4587\n",
      "\n",
      "Training Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 63.98\n",
      "Training Loss: 1.006\n",
      "\n",
      "Testing Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 110.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.56\n",
      "Test Loss: 0.964\n",
      "Time taken for epoch 38: 8.87 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 38: 53.4587\n",
      "\n",
      "Training Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 64.58\n",
      "Training Loss: 0.995\n",
      "\n",
      "Testing Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 93.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.40\n",
      "Test Loss: 0.966\n",
      "Time taken for epoch 39: 9.06 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 39: 53.4587\n",
      "\n",
      "Training Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 64.62\n",
      "Training Loss: 0.992\n",
      "\n",
      "Testing Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 118.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.68\n",
      "Test Loss: 0.960\n",
      "Time taken for epoch 40: 9.15 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 40: 53.4587\n",
      "\n",
      "Training Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 64.90\n",
      "Training Loss: 0.982\n",
      "\n",
      "Testing Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 120.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.10\n",
      "Test Loss: 0.940\n",
      "Time taken for epoch 41: 8.85 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 41: 53.4587\n",
      "\n",
      "Training Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 48.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 64.82\n",
      "Training Loss: 0.982\n",
      "\n",
      "Testing Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 89.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.90\n",
      "Test Loss: 0.967\n",
      "Time taken for epoch 42: 8.88 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 42: 53.4587\n",
      "\n",
      "Training Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 65.23\n",
      "Training Loss: 0.972\n",
      "\n",
      "Testing Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 110.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.70\n",
      "Test Loss: 0.938\n",
      "Time taken for epoch 43: 9.02 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 43: 53.4587\n",
      "\n",
      "Training Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 65.68\n",
      "Training Loss: 0.965\n",
      "\n",
      "Testing Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 105.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.51\n",
      "Test Loss: 0.934\n",
      "Time taken for epoch 44: 9.12 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 44: 53.4587\n",
      "\n",
      "Training Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 65.70\n",
      "Training Loss: 0.957\n",
      "\n",
      "Testing Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 118.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.85\n",
      "Test Loss: 0.930\n",
      "Time taken for epoch 45: 9.25 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 45: 53.4587\n",
      "\n",
      "Training Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 66.36\n",
      "Training Loss: 0.951\n",
      "\n",
      "Testing Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 115.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 67.26\n",
      "Test Loss: 0.912\n",
      "Time taken for epoch 46: 8.80 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 46: 53.4587\n",
      "\n",
      "Training Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 66.35\n",
      "Training Loss: 0.947\n",
      "\n",
      "Testing Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 89.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 67.30\n",
      "Test Loss: 0.922\n",
      "Time taken for epoch 47: 9.13 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 47: 53.4587\n",
      "\n",
      "Training Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 66.74\n",
      "Training Loss: 0.934\n",
      "\n",
      "Testing Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 67.60\n",
      "Test Loss: 0.903\n",
      "Time taken for epoch 48: 9.10 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 48: 53.4587\n",
      "\n",
      "Training Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.06\n",
      "Training Loss: 0.926\n",
      "\n",
      "Testing Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 108.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.07\n",
      "Test Loss: 0.892\n",
      "Time taken for epoch 49: 8.88 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 49: 53.4587\n",
      "\n",
      "Training Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.37\n",
      "Training Loss: 0.918\n",
      "\n",
      "Testing Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 102.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.34\n",
      "Test Loss: 0.899\n",
      "Time taken for epoch 50: 9.34 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 50: 53.4587\n",
      "\n",
      "Training Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.26\n",
      "Training Loss: 0.918\n",
      "\n",
      "Testing Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 108.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.47\n",
      "Test Loss: 0.891\n",
      "Time taken for epoch 51: 8.79 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 51: 53.4587\n",
      "\n",
      "Training Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.37\n",
      "Training Loss: 0.911\n",
      "\n",
      "Testing Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 95.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.69\n",
      "Test Loss: 0.883\n",
      "Time taken for epoch 52: 8.97 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 52: 53.4587\n",
      "\n",
      "Training Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.72\n",
      "Training Loss: 0.904\n",
      "\n",
      "Testing Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.00\n",
      "Test Loss: 0.874\n",
      "Time taken for epoch 53: 9.27 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 53: 53.4587\n",
      "\n",
      "Training Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.96\n",
      "Training Loss: 0.900\n",
      "\n",
      "Testing Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 122.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.81\n",
      "Test Loss: 0.876\n",
      "Time taken for epoch 54: 8.85 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 54: 53.4587\n",
      "\n",
      "Training Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 68.27\n",
      "Training Loss: 0.891\n",
      "\n",
      "Testing Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 88.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.60\n",
      "Test Loss: 0.871\n",
      "Time taken for epoch 55: 9.11 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 55: 53.4587\n",
      "\n",
      "Training Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 68.48\n",
      "Training Loss: 0.885\n",
      "\n",
      "Testing Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.04\n",
      "Test Loss: 0.870\n",
      "Time taken for epoch 56: 8.97 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 56: 53.4587\n",
      "\n",
      "Training Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 68.54\n",
      "Training Loss: 0.883\n",
      "\n",
      "Testing Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 118.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.26\n",
      "Test Loss: 0.862\n",
      "Time taken for epoch 57: 8.94 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 57: 53.4587\n",
      "\n",
      "Training Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 69.01\n",
      "Training Loss: 0.871\n",
      "\n",
      "Testing Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 68.93\n",
      "Test Loss: 0.873\n",
      "Time taken for epoch 58: 9.18 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 58: 53.4587\n",
      "\n",
      "Training Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 69.05\n",
      "Training Loss: 0.867\n",
      "\n",
      "Testing Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.71\n",
      "Test Loss: 0.856\n",
      "Time taken for epoch 59: 8.89 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 59: 53.4587\n",
      "\n",
      "Training Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 69.72\n",
      "Training Loss: 0.859\n",
      "\n",
      "Testing Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 99.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.76\n",
      "Test Loss: 0.841\n",
      "Time taken for epoch 60: 9.00 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 60: 53.4587\n",
      "\n",
      "Training Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 69.51\n",
      "Training Loss: 0.855\n",
      "\n",
      "Testing Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 108.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.63\n",
      "Test Loss: 0.857\n",
      "Time taken for epoch 61: 9.00 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 61: 53.4587\n",
      "\n",
      "Training Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 50.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 69.65\n",
      "Training Loss: 0.852\n",
      "\n",
      "Testing Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 120.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.22\n",
      "Test Loss: 0.846\n",
      "Time taken for epoch 62: 8.43 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 62: 53.4587\n",
      "\n",
      "Training Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 70.03\n",
      "Training Loss: 0.843\n",
      "\n",
      "Testing Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 115.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.42\n",
      "Test Loss: 0.834\n",
      "Time taken for epoch 63: 8.61 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 63: 53.4587\n",
      "\n",
      "Training Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 37.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 70.07\n",
      "Training Loss: 0.846\n",
      "\n",
      "Testing Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 96.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 69.98\n",
      "Test Loss: 0.838\n",
      "Time taken for epoch 64: 11.30 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 64: 53.4587\n",
      "\n",
      "Training Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 48.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 70.31\n",
      "Training Loss: 0.837\n",
      "\n",
      "Testing Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 111.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 70.55\n",
      "Test Loss: 0.825\n",
      "Time taken for epoch 65: 8.69 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 65: 53.4587\n",
      "\n",
      "Training Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 70.31\n",
      "Training Loss: 0.833\n",
      "\n",
      "Testing Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 91.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.22\n",
      "Test Loss: 0.815\n",
      "Time taken for epoch 66: 9.08 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 66: 53.4587\n",
      "\n",
      "Training Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 70.77\n",
      "Training Loss: 0.822\n",
      "\n",
      "Testing Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 112.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.21\n",
      "Test Loss: 0.809\n",
      "Time taken for epoch 67: 8.95 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 67: 53.4587\n",
      "\n",
      "Training Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:07<00:00, 49.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 70.80\n",
      "Training Loss: 0.820\n",
      "\n",
      "Testing Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 113.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.32\n",
      "Test Loss: 0.811\n",
      "Time taken for epoch 68: 8.60 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 68: 53.4587\n",
      "\n",
      "Training Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 71.17\n",
      "Training Loss: 0.813\n",
      "\n",
      "Testing Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 93.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.17\n",
      "Test Loss: 0.809\n",
      "Time taken for epoch 69: 9.18 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 69: 53.4587\n",
      "\n",
      "Training Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 71.00\n",
      "Training Loss: 0.812\n",
      "\n",
      "Testing Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 119.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.14\n",
      "Test Loss: 0.804\n",
      "Time taken for epoch 70: 9.00 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 70: 53.4587\n",
      "\n",
      "Training Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 71.48\n",
      "Training Loss: 0.801\n",
      "\n",
      "Testing Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.67\n",
      "Test Loss: 0.800\n",
      "Time taken for epoch 71: 8.76 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 71: 53.4587\n",
      "\n",
      "Training Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 71.90\n",
      "Training Loss: 0.790\n",
      "\n",
      "Testing Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 98.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.30\n",
      "Test Loss: 0.799\n",
      "Time taken for epoch 72: 9.26 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 72: 53.4587\n",
      "\n",
      "Training Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 72.01\n",
      "Training Loss: 0.790\n",
      "\n",
      "Testing Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.95\n",
      "Test Loss: 0.795\n",
      "Time taken for epoch 73: 8.73 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 73: 53.4587\n",
      "\n",
      "Training Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 71.87\n",
      "Training Loss: 0.788\n",
      "\n",
      "Testing Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 106.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.96\n",
      "Test Loss: 0.797\n",
      "Time taken for epoch 74: 8.88 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 74: 53.4587\n",
      "\n",
      "Training Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 45.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 72.20\n",
      "Training Loss: 0.782\n",
      "\n",
      "Testing Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 114.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 71.50\n",
      "Test Loss: 0.796\n",
      "Time taken for epoch 75: 9.23 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 75: 53.4587\n",
      "\n",
      "Training Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 72.40\n",
      "Training Loss: 0.782\n",
      "\n",
      "Testing Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 111.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.55\n",
      "Test Loss: 0.783\n",
      "Time taken for epoch 76: 8.89 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 76: 53.4587\n",
      "\n",
      "Training Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 72.73\n",
      "Training Loss: 0.772\n",
      "\n",
      "Testing Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 94.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.00\n",
      "Test Loss: 0.783\n",
      "Time taken for epoch 77: 9.33 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 77: 53.4587\n",
      "\n",
      "Training Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 72.82\n",
      "Training Loss: 0.770\n",
      "\n",
      "Testing Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 115.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.87\n",
      "Test Loss: 0.768\n",
      "Time taken for epoch 78: 9.02 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 78: 53.4587\n",
      "\n",
      "Training Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 47.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.11\n",
      "Training Loss: 0.757\n",
      "\n",
      "Testing Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 105.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.28\n",
      "Test Loss: 0.776\n",
      "Time taken for epoch 79: 8.96 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 79: 53.4587\n",
      "\n",
      "Training Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 46.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.00\n",
      "Training Loss: 0.758\n",
      "\n",
      "Testing Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 100.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.34\n",
      "Test Loss: 0.778\n",
      "Time taken for epoch 80: 9.21 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 80: 53.4587\n",
      "\n",
      "Training Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:08<00:00, 48.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.17\n",
      "Training Loss: 0.754\n",
      "\n",
      "Testing Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 115.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.40\n",
      "Test Loss: 0.782\n",
      "Time taken for epoch 81: 8.75 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 81: 53.4587\n",
      "\n",
      "Training Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:09<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.38\n",
      "Training Loss: 0.752\n",
      "\n",
      "Testing Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 61.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.44\n",
      "Test Loss: 0.779\n",
      "Time taken for epoch 82: 10.65 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 82: 53.4587\n",
      "\n",
      "Training Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.52\n",
      "Training Loss: 0.744\n",
      "\n",
      "Testing Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 105.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.12\n",
      "Test Loss: 0.758\n",
      "Time taken for epoch 83: 11.76 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 83: 53.4587\n",
      "\n",
      "Training Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.88\n",
      "Training Loss: 0.738\n",
      "\n",
      "Testing Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 74.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.28\n",
      "Test Loss: 0.756\n",
      "Time taken for epoch 84: 12.48 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 84: 53.4587\n",
      "\n",
      "Training Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.61\n",
      "Training Loss: 0.740\n",
      "\n",
      "Testing Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 72.92\n",
      "Test Loss: 0.768\n",
      "Time taken for epoch 85: 12.28 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 85: 53.4587\n",
      "\n",
      "Training Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 36.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.05\n",
      "Training Loss: 0.735\n",
      "\n",
      "Testing Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 73.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.42\n",
      "Test Loss: 0.761\n",
      "Time taken for epoch 86: 11.91 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 86: 53.4587\n",
      "\n",
      "Training Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 34.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 73.91\n",
      "Training Loss: 0.733\n",
      "\n",
      "Testing Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 77.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.20\n",
      "Test Loss: 0.753\n",
      "Time taken for epoch 87: 12.40 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 87: 53.4587\n",
      "\n",
      "Training Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 35.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.31\n",
      "Training Loss: 0.720\n",
      "\n",
      "Testing Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 77.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.42\n",
      "Test Loss: 0.756\n",
      "Time taken for epoch 88: 11.97 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 88: 53.4587\n",
      "\n",
      "Training Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.52\n",
      "Training Loss: 0.726\n",
      "\n",
      "Testing Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 76.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.62\n",
      "Test Loss: 0.747\n",
      "Time taken for epoch 89: 12.14 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 89: 53.4587\n",
      "\n",
      "Training Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.85\n",
      "Training Loss: 0.713\n",
      "\n",
      "Testing Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 78.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.38\n",
      "Test Loss: 0.754\n",
      "Time taken for epoch 90: 12.26 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 90: 53.4587\n",
      "\n",
      "Training Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 36.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.81\n",
      "Training Loss: 0.712\n",
      "\n",
      "Testing Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 77.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.76\n",
      "Test Loss: 0.745\n",
      "Time taken for epoch 91: 11.77 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 91: 53.4587\n",
      "\n",
      "Training Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.70\n",
      "Training Loss: 0.710\n",
      "\n",
      "Testing Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 77.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.79\n",
      "Test Loss: 0.747\n",
      "Time taken for epoch 92: 12.28 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 92: 53.4587\n",
      "\n",
      "Training Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 35.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 74.98\n",
      "Training Loss: 0.705\n",
      "\n",
      "Testing Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 78.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.14\n",
      "Test Loss: 0.734\n",
      "Time taken for epoch 93: 11.99 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 93: 53.4587\n",
      "\n",
      "Training Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 35.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.29\n",
      "Training Loss: 0.696\n",
      "\n",
      "Testing Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 82.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.09\n",
      "Test Loss: 0.745\n",
      "Time taken for epoch 94: 11.87 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 94: 53.4587\n",
      "\n",
      "Training Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 34.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.43\n",
      "Training Loss: 0.697\n",
      "\n",
      "Testing Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 75.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.15\n",
      "Test Loss: 0.734\n",
      "Time taken for epoch 95: 12.44 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 95: 53.4587\n",
      "\n",
      "Training Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:10<00:00, 35.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.37\n",
      "Training Loss: 0.692\n",
      "\n",
      "Testing Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 64.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.01\n",
      "Test Loss: 0.741\n",
      "Time taken for epoch 96: 12.11 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 96: 53.4587\n",
      "\n",
      "Training Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.45\n",
      "Training Loss: 0.692\n",
      "\n",
      "Testing Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 79.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.32\n",
      "Test Loss: 0.730\n",
      "Time taken for epoch 97: 12.01 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 97: 53.4587\n",
      "\n",
      "Training Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.67\n",
      "Training Loss: 0.682\n",
      "\n",
      "Testing Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 89.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 74.22\n",
      "Test Loss: 0.745\n",
      "Time taken for epoch 98: 11.95 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 98: 53.4587\n",
      "\n",
      "Training Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 75.79\n",
      "Training Loss: 0.680\n",
      "\n",
      "Testing Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:01<00:00, 65.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.98\n",
      "Test Loss: 0.739\n",
      "Time taken for epoch 99: 12.25 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 99: 53.4587\n",
      "\n",
      "Training Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:11<00:00, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 76.12\n",
      "Training Loss: 0.675\n",
      "\n",
      "Testing Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 82.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.94\n",
      "Test Loss: 0.734\n",
      "Time taken for epoch 100: 12.05 seconds\n",
      "Peak GPU memory usage: 0.49 GB\n",
      "Estimated TFLOPs for epoch 100: 53.4587\n",
      "Total training time: 1076.36 seconds\n",
      "Final model saved at: ./baseline_vit_checkpoint/VIT_CIFAR10_checkpoint_epoch_final.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Set up CUDA memory tracking\n",
    "torch.cuda.reset_peak_memory_stats(device)  # Reset memory tracking\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "    # Track peak memory usage\n",
    "    torch.cuda.memory_allocated(device)  # Ensure PyTorch updates memory usage tracking\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    \n",
    "    train_acc, train_loss = train(epoch)\n",
    "    test_acc, test_loss = test(epoch)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    print(f\"Time taken for epoch {epoch+1}: {epoch_time:.2f} seconds\")\n",
    "    # Track peak GPU memory usage\n",
    "    peak_memory = torch.cuda.max_memory_allocated(device) / (1024**3)  # Convert to GB\n",
    "    print(f\"Peak GPU memory usage: {peak_memory:.2f} GB\")\n",
    "    \n",
    "    # TFLOPs estimation for each epoch\n",
    "    input_resolution = 32  # CIFAR-10 image size\n",
    "    flops_per_image = (2 * total_params * input_resolution * input_resolution) / 1e12  # Approx. FLOPs per image\n",
    "    total_tflops = flops_per_image * len(trainloader.dataset)  # TFLOPs per epoch\n",
    "    print(f\"Estimated TFLOPs for epoch {epoch+1}: {total_tflops:.4f}\")\n",
    "    \n",
    "    if (epoch+1)%5 == 0:\n",
    "        checkpoint_path = os.path.join(save_dir, f\"VIT_CIFAR10_checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'train_acc': train_accs,\n",
    "            'test_acc': test_accs\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "# End timing after training\n",
    "total_training_time = time.time() - start_time\n",
    "print(f\"Total training time: {total_training_time:.2f} seconds\")\n",
    "\n",
    "# Save final model checkpoint\n",
    "final_checkpoint_path =  os.path.join(save_dir, f\"VIT_CIFAR10_checkpoint_epoch_final.pt\")\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict(),\n",
    "    'train_acc': train_accs,\n",
    "    'test_acc': test_accs\n",
    "}, final_checkpoint_path)\n",
    "\n",
    "print(f\"Final model saved at: {final_checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x77301c562c60>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "train_accs_gpu = train_accs.copy()\n",
    "test_accs_gpu = test_accs.copy()\n",
    "# train_accs_cpu = [acc.cpu().item() for acc in train_accs_gpu]\n",
    "# test_accs_cpu = [acc.cpu().item() for acc in test_accs_gpu]\n",
    "# print(train_accs)\n",
    "# print(test_accs)\n",
    "plt.plot(range(1, 101), train_accs_gpu, label='Train Accuracy')\n",
    "plt.plot(range(1, 101), test_accs_gpu, label='Test Accuracy')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.title(\"Train vs Test Accuracy\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_to_embed): Linear(in_features=48, out_features=128, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (trans_blocks): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): Attention(\n",
       "          (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (activation): Identity()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): FeedForward(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activation): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): ClassificationHead(\n",
       "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "from thop import profile\n",
    "def calculate_accuracy(model, dataloader):\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # print(images.shape)\n",
    "            outputs,_ = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# --- 2. Inference Speed and Latency ---\n",
    "def benchmark_inference(model, input_shape=(1, 3, 32, 32), runs=100):\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for i in range(runs):\n",
    "        output,_ = model(dummy_input)\n",
    "    torch.cuda.synchronize()\n",
    "    total_time = time.time() - start\n",
    "    latency = total_time / runs\n",
    "    throughput = runs / total_time\n",
    "    return latency, throughput\n",
    "\n",
    "# --- 3. Model Size ---\n",
    "def get_model_size(model, temp_path='temp.pth'):\n",
    "    torch.save(model.state_dict(), temp_path)\n",
    "    size_mb = os.path.getsize(temp_path) / 1e6\n",
    "    os.remove(temp_path)\n",
    "    return size_mb\n",
    "\n",
    "# --- 4. Memory Usage (estimated by RAM during execution) ---\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss / 1e6  # in MB\n",
    "    return mem\n",
    "\n",
    "# --- 5. FLOPs and Parameters ---\n",
    "def get_flops(model, input_shape=(1, 3, 32, 32)):\n",
    "    dummy_input = torch.randn(input_shape).to(device)\n",
    "    flops, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "    return flops / 1e9, params / 1e6  # GFLOPs and MParams\n",
    "\n",
    "# --- 6. Estimate Power Usage ---\n",
    "def estimate_power(flops, latency):\n",
    "    # Rough estimate: 1 GFLOP = ~0.1 Watt-sec (example heuristic)\n",
    "    energy = flops * 0.1  # Watt-seconds\n",
    "    power = energy / latency  # Watts\n",
    "    return power\n",
    "\n",
    "# --- Run all metrics ---\n",
    "accuracy = calculate_accuracy(model, testloader)\n",
    "latency, speed = benchmark_inference(model)\n",
    "model_size = get_model_size(model)\n",
    "mem_usage = get_memory_usage()\n",
    "flops, params = get_flops(model)\n",
    "power = estimate_power(flops, latency)\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Inference Latency: {latency*1000:.2f} ms\")\n",
    "print(f\"Inference Speed: {speed:.2f} samples/sec\")\n",
    "print(f\"Model Size: {model_size:.2f} MB\")\n",
    "print(f\"Memory Usage (runtime): {mem_usage:.2f} MB\")\n",
    "print(f\"FLOPs: {flops:.2f} GFLOPs\")\n",
    "print(f\"Parameters: {params:.2f} Million\")\n",
    "print(f\"Estimated Power: {power:.2f} Watts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy: 0.6880\n",
    "# Inference Latency: 1.36 ms\n",
    "# Inference Speed: 732.69 samples/sec\n",
    "# Model Size: 2.14 MB\n",
    "# Memory Usage (runtime): 1487.27 MB\n",
    "# FLOPs: 0.03 GFLOPs\n",
    "# Parameters: 0.51 Million\n",
    "# Estimated Power: 2.44 Watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-5): 6 x TransformerBlock(\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (attention): Attention(\n",
       "      (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "      (activation): Identity()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (feed_forward): FeedForward(\n",
       "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.trans_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionTransformer(\n",
    "    patch_size=patch_size,\n",
    "    max_len=max_len,\n",
    "    embed_dim=embed_dim,\n",
    "    classes=classes,\n",
    "    layers=layers,\n",
    "    channels=channels,\n",
    "    heads=heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_to_embed): Linear(in_features=48, out_features=128, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (trans_blocks): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): Attention(\n",
       "          (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (activation): Identity()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): FeedForward(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activation): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): ClassificationHead(\n",
       "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./baseline_vit_checkpoint/VIT_CIFAR10_checkpoint_epoch_final.pt', map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7394\n",
      "Inference Latency: 1.67 ms\n",
      "Inference Speed: 599.15 samples/sec\n",
      "Model Size: 2.12 MB\n",
      "Memory Usage (runtime): 1128.40 MB\n",
      "FLOPs: 0.03 GFLOPs\n",
      "Parameters: 0.51 Million\n",
      "Estimated Power: 2.00 Watts\n"
     ]
    }
   ],
   "source": [
    "# --- Run all metrics ---\n",
    "accuracy = calculate_accuracy(model, testloader)\n",
    "latency, speed = benchmark_inference(model)\n",
    "model_size = get_model_size(model)\n",
    "mem_usage = get_memory_usage()\n",
    "flops, params = get_flops(model)\n",
    "power = estimate_power(flops, latency)\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Inference Latency: {latency*1000:.2f} ms\")\n",
    "print(f\"Inference Speed: {speed:.2f} samples/sec\")\n",
    "print(f\"Model Size: {model_size:.2f} MB\")\n",
    "print(f\"Memory Usage (runtime): {mem_usage:.2f} MB\")\n",
    "print(f\"FLOPs: {flops:.2f} GFLOPs\")\n",
    "print(f\"Parameters: {params:.2f} Million\")\n",
    "print(f\"Estimated Power: {power:.2f} Watts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = VisionTransformer(\n",
    "    patch_size=patch_size,\n",
    "    max_len=max_len,\n",
    "    embed_dim=embed_dim,\n",
    "    classes=classes,\n",
    "    layers=layers,\n",
    "    channels=channels,\n",
    "    heads=heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_to_embed): Linear(in_features=48, out_features=128, bias=True)\n",
       "  (transformer): Transformer(\n",
       "    (trans_blocks): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): Attention(\n",
       "          (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (activation): Identity()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): FeedForward(\n",
       "          (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (activation): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): ClassificationHead(\n",
       "    (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (activation): GELU(approximate='none')\n",
       "    (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./baseline_vit_checkpoint/VIT_CIFAR10_checkpoint_epoch_final.pt', map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "loaded_model.load_state_dict(checkpoint['model'])\n",
    "loaded_model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "def prune_mlp_neurons(model, ratio=0.4):\n",
    "    for block in model.transformer.trans_blocks:\n",
    "        for layer in [block.feed_forward.fc1, block.feed_forward.fc2]:\n",
    "            prune.ln_structured(layer, name='weight', amount=ratio, n=1, dim=0)\n",
    "            prune.remove(layer, 'weight')\n",
    "    print(f\"🔧 Pruned {int(ratio*100)}% of MLP neurons in fc1 and fc2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_attention_heads(model, num_heads=6, keep_heads=[0, 1, 2, 3]):\n",
    "    for block in model.transformer.trans_blocks:\n",
    "        for proj_name in ['query', 'key', 'value']:\n",
    "            proj = getattr(block.attention, proj_name)\n",
    "            w = proj.weight.data\n",
    "            b = proj.bias.data if proj.bias is not None else None\n",
    "\n",
    "            head_dim = w.shape[0] // num_heads\n",
    "            kept_indices = []\n",
    "            for h in keep_heads:\n",
    "                kept_indices.extend(range(h * head_dim, (h + 1) * head_dim))\n",
    "            w_pruned = w[kept_indices, :]\n",
    "            proj.weight = torch.nn.Parameter(w_pruned)\n",
    "\n",
    "            if b is not None:\n",
    "                b_pruned = b[kept_indices]\n",
    "                proj.bias = torch.nn.Parameter(b_pruned)\n",
    "    print(f\"🔧 Kept attention heads: {keep_heads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_transformer_blocks(model, keep_ratio=0.8):\n",
    "    blocks = model.transformer.trans_blocks\n",
    "    scores = []\n",
    "    for block in blocks:\n",
    "        score = torch.norm(block.feed_forward.fc1.weight, p=2).item() + \\\n",
    "                torch.norm(block.attention.query.weight, p=2).item()\n",
    "        scores.append(score)\n",
    "\n",
    "    keep_count = int(len(blocks) * keep_ratio)\n",
    "    topk_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:keep_count]\n",
    "    new_blocks = [block for i, block in enumerate(blocks) if i in topk_idx]\n",
    "    model.transformer.trans_blocks = torch.nn.ModuleList(new_blocks)\n",
    "\n",
    "    print(f\"🔧 Kept top {keep_count}/{len(blocks)} Transformer blocks (based on norm).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Pruned 30% of MLP neurons in fc1 and fc2.\n"
     ]
    }
   ],
   "source": [
    "prune_mlp_neurons(loaded_model, ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune_transformer_blocks(loaded_model, keep_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.688\n"
     ]
    }
   ],
   "source": [
    "print(calculate_accuracy(loaded_model, testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6880\n",
      "Inference Latency: 1.35 ms\n",
      "Inference Speed: 741.93 samples/sec\n",
      "Model Size: 2.14 MB\n",
      "Memory Usage (runtime): 1492.16 MB\n",
      "FLOPs: 0.03 GFLOPs\n",
      "Parameters: 0.51 Million\n",
      "Estimated Power: 2.47 Watts\n"
     ]
    }
   ],
   "source": [
    "# --- Run all metrics ---\n",
    "accuracy = calculate_accuracy(loaded_model, testloader)\n",
    "latency, speed = benchmark_inference(loaded_model)\n",
    "model_size = get_model_size(loaded_model)\n",
    "mem_usage = get_memory_usage()\n",
    "flops, params = get_flops(loaded_model)\n",
    "power = estimate_power(flops, latency)\n",
    "\n",
    "# --- Print results ---\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Inference Latency: {latency*1000:.2f} ms\")\n",
    "print(f\"Inference Speed: {speed:.2f} samples/sec\")\n",
    "print(f\"Model Size: {model_size:.2f} MB\")\n",
    "print(f\"Memory Usage (runtime): {mem_usage:.2f} MB\")\n",
    "print(f\"FLOPs: {flops:.2f} GFLOPs\")\n",
    "print(f\"Parameters: {params:.2f} Million\")\n",
    "print(f\"Estimated Power: {power:.2f} Watts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
